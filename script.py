import logging
import asyncio
import requests
import sys
import aiohttp
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher, types, F
from aiogram.client.bot import DefaultBotProperties
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, ReplyKeyboardRemove, CallbackQuery
from aiogram.filters import Command
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from google.cloud import vision
import json
import os
import subprocess
import html
from datetime import datetime
import urllib.parse

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ JSON íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")

# JSON íŒŒì¼ ê²€ì¦
if not credentials_path or not os.path.exists(credentials_path):
    logging.error("âŒ GOOGLE_APPLICATION_CREDENTIALS íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    raise FileNotFoundError(f"í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {credentials_path}")

try:
    with open(credentials_path, "r", encoding="utf-8") as f:
        json.load(f)  # JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
    logging.info("âœ… GOOGLE_APPLICATION_CREDENTIALS JSON íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except json.JSONDecodeError as e:
    logging.error(f"âŒ JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}")
    raise ValueError(f"JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {credentials_path}")

# Google Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = vision.ImageAnnotatorClient()
logging.info("âœ… Google Cloud Vision API ì¸ì¦ ì„±ê³µ!")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.FileHandler("logfile.log"),
                        logging.StreamHandler()
                    ])
# Initialize the Vision API client
client = vision.ImageAnnotatorClient()

# ìƒìˆ˜ ì •ì˜
URL = 'https://www.pknu.ac.kr/main/163'
BASE_URL = 'https://www.pknu.ac.kr'
CATEGORY_CODES = {
    "ì „ì²´": "",
    "ê³µì§€ì‚¬í•­": "10001",
    "ë¹„êµê³¼ ì•ˆë‚´": "10002",
    "í•™ì‚¬ ì•ˆë‚´": "10003",
    "ë“±ë¡/ì¥í•™": "10004",
    "ì´ˆë¹™/ì±„ìš©": "10007"
}
TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')

# ë´‡ ë° Dispatcher ì´ˆê¸°í™”
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher(bot=bot)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
if credentials_path is None:
    logging.error("GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    with open("announcements_seen.json", "w") as f:
        f.write(credentials_path)

# ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰
credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
if credentials_path:
    try:
        with open(credentials_path, "r", encoding="utf-8") as f:
            credentials_data = f.read()
        with open("announcements_seen.json", "w", encoding="utf-8") as f:
            f.write(credentials_data)
    except Exception as e:
        logging.error(f"âŒ Failed to read credentials file: {e}")
else:
    logging.error("âŒ GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# FSM ìƒíƒœ ì •ì˜
class FilterState(StatesGroup):
    waiting_for_date = State()
    selecting_category = State()

# ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
def parse_date(date_str):
    try:
        return datetime.strptime(date_str, "%Y-%m-%d")
    except ValueError as ve:
        logging.error(f"Date parsing error for {date_str}: {ve}")
        return None

# JSON íŒŒì¼ ë¡œë“œ (ìœ ì—°í•œ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬)
def load_seen_announcements():
    try:
        with open("announcements_seen.json", "r", encoding="utf-8") as f:
            seen_data = json.load(f)
            return {(item[0], item[1]) if len(item) == 2 else tuple(item) for item in seen_data}
    except (FileNotFoundError, json.JSONDecodeError):
        return set()

# JSON íŒŒì¼ ì €ì¥ (ì¤‘ë³µ ì œê±° í›„ ë¦¬ìŠ¤íŠ¸ ë³€í™˜)
def save_seen_announcements(seen):
    try:
        with open("announcements_seen.json", "w", encoding="utf-8") as f:
            json.dump([list(item) for item in seen], f, ensure_ascii=False, indent=4)
        push_changes()
    except Exception as e:
        logging.error(f"âŒ Failed to save announcements_seen.json and push to GitHub: {e}")

# ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ (URL ì²˜ë¦¬ ê°œì„ )
async def fetch_url(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url, timeout=10) as response:
            return await response.text()

async def get_school_notices(category=""):
    try:
        category_url = f"{URL}?cd={category}" if category else URL
        html_content = await fetch_url(category_url)  # âœ… ë¹„ë™ê¸° ìš”ì²­
        soup = BeautifulSoup(html_content, 'html.parser')

        notices = []
        for tr in soup.find_all("tr"):
            title_td = tr.find("td", class_="bdlTitle")
            user_td = tr.find("td", class_="bdlUser")
            date_td = tr.find("td", class_="bdlDate")

            if title_td and title_td.find("a") and user_td and date_td:
                a_tag = title_td.find("a")
                title = a_tag.get_text(strip=True)
                href = a_tag.get("href")

                if href.startswith("/"):
                    href = BASE_URL + href
                elif href.startswith("?"):
                    href = BASE_URL + "/main/163" + href
                elif not href.startswith("http"):
                    href = BASE_URL + "/" + href

                department = user_td.get_text(strip=True)
                date = date_td.get_text(strip=True)
                notices.append((title, href, department, date))

        notices.sort(key=lambda x: parse_date(x[3]) or datetime.min, reverse=True)
        return notices
    except Exception as e:
        logging.exception("âŒ Error in get_school_notices")
        return []

# URLë‚´ ì´ë¯¸ì§€ ì¶”ì¶œ
async def extract_content(url):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                html_content = await response.text()

        soup = BeautifulSoup(html_content, 'html.parser')

        # Extract text
        paragraphs = soup.find_all('p')
        text = ' '.join([para.get_text() for para in paragraphs])

        # Extract images
        images = soup.find_all('img')
        image_urls = [img['src'] for img in images if 'src' in img.attrs]

        return text, image_urls
    except Exception as e:
        logging.error(f"âŒ Failed to fetch content from {url}: {e}")
        return "", []

# ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬
async def analyze_image(image_url):
    if not image_url.startswith(('http://', 'https://')):
        image_url = 'https://' + image_url.lstrip('/')

    logging.info(f"Analyzing image URL: {image_url}")

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(image_url, timeout=10) as response:
                image_content = await response.read()  # âœ… ë¹„ë™ê¸°ì ìœ¼ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ

        image = vision.Image(content=image_content)

        # Text detection
        response = client.text_detection(image=image)
        texts = response.text_annotations
        text_analysis = [text.description for text in texts]

        # Label detection
        response = client.label_detection(image=image)
        labels = response.label_annotations
        label_analysis = [label.description for label in labels]

        return text_analysis, label_analysis
    except Exception as e:
        logging.error(f"âŒ Failed to fetch image: {e}")
        return [], []
  
# ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ í™•ì¸ ë° ì•Œë¦¼ ì „ì†¡
async def check_for_new_notices():
    logging.info("Checking for new notices...")
    
    seen_announcements = load_seen_announcements()
    logging.info(f"Loaded seen announcements: {seen_announcements}")

    current_notices = await get_school_notices()  # âœ… ë¹„ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
    logging.info(f"Fetched current notices: {current_notices}")

    seen_titles_urls = {(title, url) for title, url, *_ in seen_announcements}

    new_notices = [
        (title, href, department, date) for title, href, department, date in current_notices
        if (title, href) not in seen_titles_urls
    ]
    logging.info(f"DEBUG: New notices detected: {new_notices}")

    if new_notices:
        for notice in new_notices:
            await send_notification(notice)
        seen_announcements.update(new_notices)
        save_seen_announcements(seen_announcements)
        logging.info(f"DEBUG: Updated seen announcements (after update): {seen_announcements}")
    else:
        logging.info("âœ… ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        
# GitHub Push (PAT ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€)
def push_changes():
    try:
        pat = os.environ.get("MY_PAT")
        if not pat:
            logging.error("âŒ GitHub PATê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Pushë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            return
        
        os.environ["GIT_ASKPASS"] = "echo"
        os.environ["GIT_PASSWORD"] = pat

        subprocess.run(["git", "config", "--global", "credential.helper", "store"], check=True)
        subprocess.run(["git", "add", "announcements_seen.json"], check=True)
        subprocess.run(["git", "commit", "-m", "Update announcements_seen.json"], check=True)
        subprocess.run(["git", "push", "origin", "main"], check=True)

        logging.info("âœ… Successfully pushed changes to GitHub.")
    except subprocess.CalledProcessError as e:
        logging.error(f"âŒ ERROR: Failed to push changes to GitHub: {e}")

# ìˆ˜ë™ìœ¼ë¡œ ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ í™•ì¸
@dp.message(Command("checknotices"))
async def manual_check_notices(message: types.Message):
    new_notices = await check_for_new_notices()
    if new_notices:
        await message.answer(f"ğŸ“¢ {len(new_notices)}ê°œì˜ ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤!")
    else:
        await message.answer("âœ… ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì•Œë¦¼ ì „ì†¡
async def send_notification(notice):
    title, href, department, date = notice
    
    # Extract text and images
    text, image_urls = extract_content(href)
    
    # Prepare message
    message_text = f"[ë¶€ê²½ëŒ€ <b>{html.escape(department)}</b> ê³µì§€ì‚¬í•­ ì—…ë°ì´íŠ¸]\n\n"
    message_text += f"<b>{html.escape(title)}</b>\n\n{html.escape(date)}\n\n{text}"
    
    # Analyze images and append to summary
    for image_url in image_urls:
        text_analysis, label_analysis = analyze_image(image_url)
        if label_analysis:
            message_text += f"\n\nì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {', '.join(label_analysis)}"
    
    keyboard = InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="ìì„¸íˆ ë³´ê¸°", url=href)]])
    await bot.send_message(chat_id=CHAT_ID, text=message_text, reply_markup=keyboard)

# ë©”ì‹œì§€ ID ì €ì¥ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜

# /start ëª…ë ¹ì–´ ì²˜ë¦¬
@dp.message(Command("start"))
async def start_command(message: types.Message):
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸ“…ë‚ ì§œ ì…ë ¥", callback_data="filter_date"), InlineKeyboardButton(text="ğŸ“¢ì „ì²´ ê³µì§€ì‚¬í•­", callback_data="all_notices")]
    ])
    await message.answer("ì•ˆë…•í•˜ì„¸ìš”! ê³µì§€ì‚¬í•­ ë´‡ì…ë‹ˆë‹¤.\n\nì•„ë˜ ë²„íŠ¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”:", reply_markup=keyboard)

# ë‚ ì§œ ì…ë ¥ ìš”ì²­ ì²˜ë¦¬
@dp.callback_query(F.data == "filter_date")
async def callback_filter_date(callback: CallbackQuery, state: FSMContext):
    await callback.message.answer("MM/DD í˜•ì‹ìœ¼ë¡œ ë‚ ì§œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 01/31)")
    await state.set_state(FilterState.waiting_for_date)
    await callback.answer()

# ì „ì²´ ê³µì§€ì‚¬í•­ ë²„íŠ¼ í´ë¦­ ì‹œ ì¹´í…Œê³ ë¦¬ ì„ íƒ ë©”ë‰´ í‘œì‹œ
@dp.callback_query(F.data == "all_notices")
async def callback_all_notices(callback: CallbackQuery, state: FSMContext):
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text=category, callback_data=f"category_{code}")] for category, code in CATEGORY_CODES.items()
    ])
    await callback.message.answer("ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", reply_markup=keyboard)
    await state.set_state(FilterState.selecting_category)
    await callback.answer()

# ì¹´í…Œê³ ë¦¬ ì„ íƒ ì‹œ í•´ë‹¹ ê³µì§€ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
@dp.callback_query(F.data.startswith("category_"))
async def callback_category_selection(callback: CallbackQuery, state: FSMContext):
    category_code = callback.data.split("_")[1]
    notices = get_school_notices(category_code)
    
    if not notices:
        await callback.message.answer("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for notice in notices[:7]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            await send_notification(notice)
    
    await state.clear()
    await callback.answer()

# ë‚ ì§œ ì…ë ¥ ì²˜ë¦¬
@dp.message(F.text)
async def process_date_input(message: types.Message, state: FSMContext):
    current_state = await state.get_state()
    logging.info(f"Current FSM state raw: {current_state}")

    # ìƒíƒœ ë¹„êµ ìˆ˜ì •
    if current_state != FilterState.waiting_for_date.state:
        logging.warning("Received date input, but state is incorrect.")
        return

    input_text = message.text.strip()
    logging.info(f"Received date input: {input_text}")

    current_year = datetime.now().year
    full_date_str = f"{current_year}-{input_text.replace('/', '-')}"
    logging.info(f"Converted full date string: {full_date_str}")

    filter_date = parse_date(full_date_str)

    if filter_date is None:
        await message.answer("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. MM/DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return

    notices = [n for n in get_school_notices() if parse_date(n[3]) == filter_date]

    if not notices:
        logging.info(f"No notices found for {full_date_str}")
        await message.answer(f"ğŸ“¢ {input_text}ì˜ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        await message.answer(f"ğŸ“¢ {input_text}ì˜ ê³µì§€ì‚¬í•­ì…ë‹ˆë‹¤.", reply_markup=ReplyKeyboardRemove())
        for notice in notices:
            await send_notification(notice)

    logging.info("Clearing FSM state.")
    await state.clear()

async def run_bot():
    """
    10ë¶„(600ì´ˆ) ë™ì•ˆë§Œ ë´‡ì„ ì‹¤í–‰í•œ í›„ ìë™ ì¢…ë£Œí•˜ëŠ” í•¨ìˆ˜.
    """
    try:
        logging.info("ğŸš€ Starting bot polling for 10 minutes...")
        polling_task = asyncio.create_task(dp.start_polling(bot))  # í´ë§ì„ ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
        await asyncio.sleep(600)  # 10ë¶„ ëŒ€ê¸°
        logging.info("ğŸ›‘ Stopping bot polling after 10 minutes...")
        polling_task.cancel()  # í´ë§ íƒœìŠ¤í¬ ì·¨ì†Œ
        await dp.stop_polling()  # Dispatcher ì¢…ë£Œ
    except Exception as e:
        logging.error(f"âŒ Bot error: {e}")
    finally:
        await bot.session.close()  # ë´‡ ì„¸ì…˜ ë‹«ê¸°
        logging.info("âœ… Bot session closed.")

if __name__ == '__main__':
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    try:
        asyncio.run(run_bot())
    except RuntimeError:
        logging.error("âŒ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.")

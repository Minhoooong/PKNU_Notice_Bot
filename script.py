import logging
import asyncio
import sys
import aiohttp
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher, types, F
from aiogram.client.bot import DefaultBotProperties
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, ReplyKeyboardRemove, CallbackQuery
from aiogram.filters import Command
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from collections import Counter
import json
import os
import subprocess
import html
from datetime import datetime
import urllib.parse
import kss
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration

MODEL_NAME = "EbanLee/kobart-summary-v3"
tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)
model = BartForConditionalGeneration.from_pretrained(MODEL_NAME)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logfile.log"),
        logging.StreamHandler()
    ]
)

# --- ìƒìˆ˜ ë° í™˜ê²½ ë³€ìˆ˜ ---
URL = 'https://www.pknu.ac.kr/main/163'
BASE_URL = 'https://www.pknu.ac.kr'
CATEGORY_CODES = {
    "ì „ì²´": "",
    "ê³µì§€ì‚¬í•­": "10001",
    "ë¹„êµê³¼ ì•ˆë‚´": "10002",
    "í•™ì‚¬ ì•ˆë‚´": "10003",
    "ë“±ë¡/ì¥í•™": "10004",
    "ì´ˆë¹™/ì±„ìš©": "10007"
}
TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')

# --- ë´‡ ë° Dispatcher ì´ˆê¸°í™” ---
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher(bot=bot)

# --- FSM ìƒíƒœ ì •ì˜ ---
class FilterState(StatesGroup):
    waiting_for_date = State()
    selecting_category = State()

# --- ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜ ---
def parse_date(date_str):
    try:
        return datetime.strptime(date_str, "%Y-%m-%d")
    except ValueError as ve:
        logging.error(f"Date parsing error for {date_str}: {ve}")
        return None

# --- HTTP ìš”ì²­ í•¨ìˆ˜ (fetch_url) ---
async def fetch_url(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url, timeout=10) as response:
            return await response.text()

# --- ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ---
async def get_school_notices(category=""):
    try:
        category_url = f"{URL}?cd={category}" if category else URL
        html_content = await fetch_url(category_url)
        soup = BeautifulSoup(html_content, 'html.parser')
        notices = []
        for tr in soup.find_all("tr"):
            title_td = tr.find("td", class_="bdlTitle")
            user_td = tr.find("td", class_="bdlUser")
            date_td = tr.find("td", class_="bdlDate")
            if title_td and title_td.find("a") and user_td and date_td:
                a_tag = title_td.find("a")
                title = a_tag.get_text(strip=True)
                href = a_tag.get("href")
                if href.startswith("/"):
                    href = BASE_URL + href
                elif href.startswith("?"):
                    href = BASE_URL + "/main/163" + href
                elif not href.startswith("http"):
                    href = BASE_URL + "/" + href
                department = user_td.get_text(strip=True)
                date = date_td.get_text(strip=True)
                notices.append((title, href, department, date))
        notices.sort(key=lambda x: parse_date(x[3]) or datetime.min, reverse=True)
        return notices
    except Exception as e:
        logging.exception("âŒ Error in get_school_notices")
        return []

def extract_key_sentences(text, top_n=5):
    """
    ì¤‘ìš” ë¬¸ì¥ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜.
    TextRank ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ ìƒìœ„ Nê°œì˜ ë¬¸ì¥ì„ ì„ íƒ.
    """
    sentences = kss.split_sentences(text)
    
    # ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ìš” ë‹¨ì–´ë¥¼ ì„ ë³„
    word_count = Counter(" ".join(sentences).split())
    important_words = [word for word, count in word_count.most_common(20)]  # ìƒìœ„ 20ê°œ ë‹¨ì–´ ì„ íƒ
    
    # ì¤‘ìš” ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ë§Œ í•„í„°ë§
    key_sentences = []
    for sentence in sentences:
        if any(word in sentence for word in important_words):
            key_sentences.append(sentence)

    return key_sentences[:top_n]  # ìƒìœ„ Nê°œ ë¬¸ì¥ ì„ íƒ

def summarize_paragraphs(text):
    """
    ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ìš”ì•½í•˜ëŠ” ëŒ€ì‹ , ì¤‘ìš” ë¬¸ì¥ì„ ë¨¼ì € ì¶”ì¶œí•œ í›„ ìš”ì•½.
    """
    paragraphs = text.split("\n")  # ë¬¸ë‹¨ ë¶„ë¦¬
    cleaned_paragraphs = [" ".join(kss.split_sentences(para)) for para in paragraphs if para.strip()]
    
    # ë¬¸ë‹¨ë³„ ì¤‘ìš” ë¬¸ì¥ ì¶”ì¶œ
    key_sentences = []
    for para in cleaned_paragraphs:
        key_sentences.extend(extract_key_sentences(para, top_n=3))

    # ìš”ì•½ ëª¨ë¸ ì ìš©
    full_text = " ".join(key_sentences)
    inputs = tokenizer(full_text, return_tensors="pt", padding=True, truncation=True, max_length=1024)
    
    summary_ids = model.generate(
        input_ids=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        num_beams=6,
        length_penalty=1.0,
        max_length=100,  # ì ì ˆí•œ ìš”ì•½ ê¸¸ì´ ì¡°ì ˆ
        min_length=30,
        repetition_penalty=1.5,
        no_repeat_ngram_size=15,
    )
    
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

# --- ì½˜í…ì¸  ì¶”ì¶œ: bdvTxt_wrap ì˜ì—­ ë‚´ í…ìŠ¤íŠ¸ì™€ /upload/ ì´ë¯¸ì§€ í¬ë¡¤ë§ ---
async def extract_content(url):
    """
    ì£¼ì–´ì§„ URLì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í¬ë¡¤ë§í•œ í›„, ìš”ì•½í•˜ì—¬ ë°˜í™˜
    """
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                html_content = await response.text()

        soup = BeautifulSoup(html_content, 'html.parser')
        container = soup.find("div", class_="bdvTxt_wrap")  # ê³µì§€ì‚¬í•­ ë³¸ë¬¸
        
        if not container:
            logging.error("âŒ bdvTxt_wrap ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return "", []

        # --- í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
        paragraphs = container.find_all('p')
        raw_text = "\n".join([para.get_text(separator=" ", strip=True) for para in paragraphs])
        
        # --- ìš”ì•½ ì ìš© ---
        summary_text = summarize_paragraphs(raw_text)  # âœ… ë³€ê²½ëœ í•¨ìˆ˜ í˜¸ì¶œ

        # --- ì´ë¯¸ì§€ ì¶”ì¶œ (/upload/ ë§Œ í¬í•¨) ---
        images = container.find_all('img')
        image_urls = []
        for img in images:
            src = img.get('src')
            if src and "/upload/" in src:
                if not src.startswith(("http://", "https://")):
                    src = urllib.parse.urljoin(url, src)
                if await is_valid_url(src):
                    image_urls.append(src)

        return summary_text, image_urls
    except Exception as e:
        logging.error(f"âŒ Failed to fetch content from {url}: {e}")
        return "", []

async def is_valid_url(url):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.head(url, timeout=10) as response:
                return response.status == 200
    except Exception as e:
        logging.error(f"âŒ Invalid image URL: {url}, error: {e}")
    return False

# --- JSON íŒŒì¼ ì²˜ë¦¬ (ê³µì§€ì‚¬í•­ ì¤‘ë³µ ì²´í¬) ---
def load_seen_announcements():
    try:
        with open("announcements_seen.json", "r", encoding="utf-8") as f:
            seen_data = json.load(f)
            return {(item[0], item[1]) if len(item) == 2 else tuple(item) for item in seen_data}
    except (FileNotFoundError, json.JSONDecodeError):
        return set()

def save_seen_announcements(seen):
    try:
        with open("announcements_seen.json", "w", encoding="utf-8") as f:
            json.dump([list(item) for item in seen], f, ensure_ascii=False, indent=4)
        push_changes()
    except Exception as e:
        logging.error(f"âŒ Failed to save announcements_seen.json and push to GitHub: {e}")

def push_changes():
    try:
        pat = os.environ.get("MY_PAT")
        if not pat:
            logging.error("âŒ GitHub PATê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Pushë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            return
        os.environ["GIT_ASKPASS"] = "echo"
        os.environ["GIT_PASSWORD"] = pat
        subprocess.run(["git", "config", "--global", "credential.helper", "store"], check=True)
        subprocess.run(["git", "add", "announcements_seen.json"], check=True)
        subprocess.run(["git", "commit", "-m", "Update announcements_seen.json"], check=True)
        subprocess.run(["git", "push", "origin", "main"], check=True)
        logging.info("âœ… Successfully pushed changes to GitHub.")
    except subprocess.CalledProcessError as e:
        logging.error(f"âŒ ERROR: Failed to push changes to GitHub: {e}")

async def check_for_new_notices():
    logging.info("Checking for new notices...")
    seen_announcements = load_seen_announcements()
    logging.info(f"Loaded seen announcements: {seen_announcements}")
    current_notices = await get_school_notices()
    logging.info(f"Fetched current notices: {current_notices}")
    seen_titles_urls = {(title, url) for title, url, *_ in seen_announcements}
    new_notices = [
        (title, href, department, date) for title, href, department, date in current_notices
        if (title, href) not in seen_titles_urls
    ]
    logging.info(f"DEBUG: New notices detected: {new_notices}")
    if new_notices:
        for notice in new_notices:
            await send_notification(notice)
        seen_announcements.update(new_notices)
        save_seen_announcements(seen_announcements)
        logging.info(f"DEBUG: Updated seen announcements (after update): {seen_announcements}")
    else:
        logging.info("âœ… ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

@dp.message(Command("checknotices"))
async def manual_check_notices(message: types.Message):
    new_notices = await check_for_new_notices()
    if new_notices:
        await message.answer(f"ğŸ“¢ {len(new_notices)}ê°œì˜ ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤!")
    else:
        await message.answer("âœ… ìƒˆë¡œìš´ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

async def send_notification(notice):
    title, href, department, date = notice
    summary_text, image_urls = await extract_content(href)
    message_text = f"[ë¶€ê²½ëŒ€ <b>{html.escape(department)}</b> ê³µì§€ì‚¬í•­ ì—…ë°ì´íŠ¸]\n\n"
    message_text += f"<b>{html.escape(title)}</b>\n\n{html.escape(date)}\n\n"
    message_text += f"{html.escape(summary_text)}"
    if image_urls:
        message_text += "\n\n[ì²¨ë¶€ ì´ë¯¸ì§€]\n" + "\n".join(image_urls)
    keyboard = InlineKeyboardMarkup(inline_keyboard=[[InlineKeyboardButton(text="ìì„¸íˆ ë³´ê¸°", url=href)]])
    await bot.send_message(chat_id=CHAT_ID, text=message_text, reply_markup=keyboard)

@dp.message(Command("start"))
async def start_command(message: types.Message):
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸ“…ë‚ ì§œ ì…ë ¥", callback_data="filter_date"),
         InlineKeyboardButton(text="ğŸ“¢ì „ì²´ ê³µì§€ì‚¬í•­", callback_data="all_notices")]
    ])
    await message.answer("ì•ˆë…•í•˜ì„¸ìš”! ê³µì§€ì‚¬í•­ ë´‡ì…ë‹ˆë‹¤.\n\nì•„ë˜ ë²„íŠ¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”:", reply_markup=keyboard)

@dp.callback_query(F.data == "filter_date")
async def callback_filter_date(callback: CallbackQuery, state: FSMContext):
    try:
        await callback.message.answer("MM/DD í˜•ì‹ìœ¼ë¡œ ë‚ ì§œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 01/31)")
    except Exception:
        pass
    await state.set_state(FilterState.waiting_for_date)
    try:
        await callback.answer()
    except Exception:
        pass

@dp.callback_query(F.data == "all_notices")
async def callback_all_notices(callback: CallbackQuery, state: FSMContext):
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text=category, callback_data=f"category_{code}")]
         for category, code in CATEGORY_CODES.items()
    ])
    try:
        await callback.message.answer("ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", reply_markup=keyboard)
    except Exception:
        pass
    await state.set_state(FilterState.selecting_category)
    try:
        await callback.answer()
    except Exception:
        pass

@dp.callback_query(F.data.startswith("category_"))
async def callback_category_selection(callback: CallbackQuery, state: FSMContext):
    category_code = callback.data.split("_")[1]
    notices = await get_school_notices(category_code)
    if not notices:
        try:
            await callback.message.answer("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception:
            pass
    else:
        for notice in notices[:7]:
            await send_notification(notice)
    await state.clear()
    try:
        await callback.answer()
    except Exception:
        pass

@dp.message(F.text)
async def process_date_input(message: types.Message, state: FSMContext):
    current_state = await state.get_state()
    logging.info(f"Current FSM state raw: {current_state}")
    if current_state != FilterState.waiting_for_date.state:
        logging.warning("Received date input, but state is incorrect.")
        return
    input_text = message.text.strip()
    logging.info(f"Received date input: {input_text}")
    current_year = datetime.now().year
    full_date_str = f"{current_year}-{input_text.replace('/', '-')}"
    logging.info(f"Converted full date string: {full_date_str}")
    filter_date = parse_date(full_date_str)
    if filter_date is None:
        await message.answer("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. MM/DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        return
    notices = [n for n in await get_school_notices() if parse_date(n[3]) == filter_date]
    if not notices:
        logging.info(f"No notices found for {full_date_str}")
        await message.answer(f"ğŸ“¢ {input_text}ì˜ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        await message.answer(f"ğŸ“¢ {input_text}ì˜ ê³µì§€ì‚¬í•­ì…ë‹ˆë‹¤.", reply_markup=ReplyKeyboardRemove())
        for notice in notices:
            await send_notification(notice)
    logging.info("Clearing FSM state.")
    await state.clear()

async def run_bot():
    try:
        logging.info("ğŸš€ Starting bot polling for 10 minutes...")
        polling_task = asyncio.create_task(dp.start_polling(bot))
        await asyncio.sleep(600)
        logging.info("ğŸ›‘ Stopping bot polling after 10 minutes...")
        polling_task.cancel()
        await dp.stop_polling()
    except Exception as e:
        logging.error(f"âŒ Bot error: {e}")
    finally:
        await bot.session.close()
        logging.info("âœ… Bot session closed.")

if __name__ == '__main__':
    if sys.platform.startswith("win"):
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    try:
        asyncio.run(run_bot())
    except RuntimeError as e:
        logging.error(f"âŒ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
